{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.datasets import StandardDataset",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Pre-Processing Ansätze ausprobieren**\n",
    "\n",
    "- **Beispiele für Techniken:**\n",
    "  - **Reweighing:** Anpassung der Gewichtungen der Datenpunkte, um Ungleichgewichte in den sensiblen Merkmalen auszugleichen.\n",
    "  - **Disparate Impact Remover:** Transformation der Daten, um den Einfluss sensibler Merkmale auf die Zielvariable zu reduzieren.\n",
    "\n",
    "- **Aufgabe:**\n",
    "  - Wende eine Pre-Processing Methode an und bewerte deren Einfluss auf die Fairness- und Performance-Metriken des Modells.\n",
    "  \n",
    "  [Tutorial zur Verwendung von AIF360 (Credit Scoring Beispiel)](https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_credit_scoring.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Untersuchung und Visualisierung zusätzlicher Biases im Datensatz**\n",
    "\n",
    "- **Aufgabe:**\n",
    "  - Erstelle Visualisierungen (z.B. Histogramme, Boxplots) zur Analyse der Verteilung verschiedener Merkmale in Bezug auf das sensitive Merkmal `SEX` und das Ziellabel `default`.\n",
    "  - Identifiziere mögliche Korrelationen oder Muster, die auf weitere Fairness-Herausforderungen hinweisen könnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Vergleich verschiedener Fairness-Metriken**\n",
    "\n",
    "- **Beispiele für Fairness-Metriken:**\n",
    "  - **Demographic Parity (Demografische Parität)**\n",
    "  - **Equal Opportunity (Gleiche Chancen)**\n",
    "  - **Predictive Parity (Vorhersageparität)**\n",
    "\n",
    "- **Aufgabe:**\n",
    "  - Berechne verschiedene Fairness-Metriken für die trainierten Modelle.\n",
    "  - Diskutiere, wie sich die Wahl der Metrik auf die Bewertung der Modellfairness auswirkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
