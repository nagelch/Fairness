{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom aif360.datasets import GermanDataset\nfrom aif360.datasets import StandardDataset\nfrom aif360.algorithms.preprocessing import Reweighing\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom fairlearn.reductions import ExponentiatedGradient, DemographicParity\nfrom fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\npip install 'aif360[AdversarialDebiasing]'\nWARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\npip install 'aif360[AdversarialDebiasing]'\nWARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\npip install 'aif360[inFairness]'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\ndataset = (\n    pd.read_excel(io=data_url, header=1)\n    .drop(columns=[\"ID\"])\n    .rename(columns={\"PAY_0\": \"PAY_1\", \"default payment next month\": \"default\"})\n)\n\ndataset.shape\n\ncategorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n\nfor col_name in categorical_features:\n    dataset[col_name] = dataset[col_name].astype(\"category\")\n\nY, A = dataset.loc[:, \"default\"], dataset.loc[:, \"SEX\"]\nX = pd.get_dummies(dataset.drop(columns=[\"default\", \"SEX\"]))\n\nA_str = A.map({1: \"male\", 2: \"female\"})\n\nY.value_counts(normalize=True)\n\nX.loc[:, \"Interest\"] = np.random.normal(loc=2 * Y, scale=A)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. **Pre-Processing Ansätze ausprobieren**\n\n- **Beispiele für Techniken:**\n  - **Reweighing:** Anpassung der Gewichtungen der Datenpunkte, um Ungleichgewichte in den sensiblen Merkmalen auszugleichen.\n  - **Disparate Impact Remover:** Transformation der Daten, um den Einfluss sensibler Merkmale auf die Zielvariable zu reduzieren.\n\n- **Aufgabe:**\n  - Wende eine Pre-Processing Methode an und bewerte deren Einfluss auf die Fairness- und Performance-Metriken des Modells.\n  \n  [Tutorial zur Verwendung von AIF360 (Credit Scoring Beispiel)](https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_credit_scoring.ipynb)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(30000, 24)"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### 2. **Untersuchung und Visualisierung zusätzlicher Biases im Datensatz**\n\n- **Aufgabe:**\n  - Erstelle Visualisierungen (z.B. Histogramme, Boxplots) zur Analyse der Verteilung verschiedener Merkmale in Bezug auf das sensitive Merkmal `SEX` und das Ziellabel `default`.\n  - Identifiziere mögliche Korrelationen oder Muster, die auf weitere Fairness-Herausforderungen hinweisen könnten.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. **Vergleich verschiedener Fairness-Metriken**\n\n- **Beispiele für Fairness-Metriken:**\n  - **Demographic Parity (Demografische Parität)**\n  - **Equal Opportunity (Gleiche Chancen)**\n  - **Predictive Parity (Vorhersageparität)**\n\n- **Aufgabe:**\n  - Berechne verschiedene Fairness-Metriken für die trainierten Modelle.\n  - Diskutiere, wie sich die Wahl der Metrik auf die Bewertung der Modellfairness auswirkt.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":false},"outputs":[],"execution_count":null}]}